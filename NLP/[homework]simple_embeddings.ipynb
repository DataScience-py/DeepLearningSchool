{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ot3c4fjZwC4T"
      },
      "source": [
        "<img src=\"https://s8.hostingkartinok.com/uploads/images/2018/08/308b49fcfbc619d629fe4604bceb67ac.jpg\" width=500, height=450>\n",
        "<h3 style=\"text-align: center;\"><b>Физтех-Школа Прикладной математики и информатики (ФПМИ) МФТИ</b></h3>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P2JdzEXmwRU5"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fc8iHXIVwDwj"
      },
      "source": [
        "***Some parts of the notebook are almost the copy of [ mmta-team course](https://github.com/mmta-team/mmta_fall_2020). Special thanks to mmta-team for making them publicly available. [Original notebook](https://github.com/mmta-team/mmta_fall_2020/blob/master/tasks/01_word_embeddings/task_word_embeddings.ipynb).***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7D0wm5jt6j0U"
      },
      "source": [
        "<b> Прочитайте семинар, пожалуйста, для успешного выполнения домашнего задания. В конце ноутка напишите свой вывод. Работа без вывода оценивается ниже."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BIWqBuEa6j0b"
      },
      "source": [
        "## Задача поиска схожих по смыслу предложений"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NUkwMPLA6j0g"
      },
      "source": [
        "Мы будем ранжировать вопросы [StackOverflow](https://stackoverflow.com) на основе семантического векторного представления"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dNRXIEfu5a3Q"
      },
      "source": [
        "До этого в курсе не было речи про задачу ранжировния, поэтому введем математическую формулировку"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uS9FwWNd5a3S"
      },
      "source": [
        "## Задача ранжирования(Learning to Rank)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wdwY9-f75a3T"
      },
      "source": [
        "* $X$ - множество объектов\n",
        "* $X^l = \\{x_1, x_2, ..., x_l\\}$ - обучающая выборка\n",
        "<br>На обучающей выборке задан порядок между некоторыми элементами, то есть нам известно, что некий объект выборки более релевантный для нас, чем другой:\n",
        "* $i \\prec j$ - порядок пары индексов объектов на выборке $X^l$ c индексами $i$ и $j$\n",
        "### Задача:\n",
        "построить ранжирующую функцию $a$ : $X \\rightarrow R$ такую, что\n",
        "$$i \\prec j \\Rightarrow a(x_i) < a(x_j)$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WG2IGBsh5a3U"
      },
      "source": [
        "<img src=\"https://d25skit2l41vkl.cloudfront.net/wp-content/uploads/2016/12/Featured-Image.jpg\" width=500, height=450>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MQk_rolFwT_h"
      },
      "source": [
        "### Embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xUe1PGXn6j0l"
      },
      "source": [
        "Будем использовать предобученные векторные представления слов на постах Stack Overflow.<br>\n",
        "[A word2vec model trained on Stack Overflow posts](https://github.com/vefstathiou/SO_word2vec)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mYkI54Y-rk7a",
        "outputId": "79e4b5e0-9e6b-47b9-e41d-6361ba3b1e8d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2025-09-22 18:22:25--  https://zenodo.org/record/1199620/files/SO_vectors_200.bin?download=1\n",
            "Resolving zenodo.org (zenodo.org)... 188.185.48.194, 188.185.43.25, 188.185.45.92, ...\n",
            "Connecting to zenodo.org (zenodo.org)|188.185.48.194|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 MOVED PERMANENTLY\n",
            "Location: /records/1199620/files/SO_vectors_200.bin [following]\n",
            "--2025-09-22 18:22:26--  https://zenodo.org/records/1199620/files/SO_vectors_200.bin\n",
            "Reusing existing connection to zenodo.org:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1453905423 (1.4G) [application/octet-stream]\n",
            "Saving to: ‘SO_vectors_200.bin?download=1.1’\n",
            "\n",
            "SO_vectors_200.bin?   0%[                    ]   3.02M  1.45MB/s               ^C\n"
          ]
        }
      ],
      "source": [
        "!wget https://zenodo.org/record/1199620/files/SO_vectors_200.bin?download=1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting gensim\n",
            "  Downloading gensim-4.3.3-cp311-cp311-win_amd64.whl.metadata (8.2 kB)\n",
            "Collecting numpy<2.0,>=1.18.5 (from gensim)\n",
            "  Downloading numpy-1.26.4-cp311-cp311-win_amd64.whl.metadata (61 kB)\n",
            "Collecting scipy<1.14.0,>=1.7.0 (from gensim)\n",
            "  Downloading scipy-1.13.1-cp311-cp311-win_amd64.whl.metadata (60 kB)\n",
            "Collecting smart-open>=1.8.1 (from gensim)\n",
            "  Downloading smart_open-7.3.1-py3-none-any.whl.metadata (24 kB)\n",
            "Collecting wrapt (from smart-open>=1.8.1->gensim)\n",
            "  Downloading wrapt-1.17.3-cp311-cp311-win_amd64.whl.metadata (6.5 kB)\n",
            "Downloading gensim-4.3.3-cp311-cp311-win_amd64.whl (24.0 MB)\n",
            "   ---------------------------------------- 0.0/24.0 MB ? eta -:--:--\n",
            "    --------------------------------------- 0.5/24.0 MB 3.4 MB/s eta 0:00:07\n",
            "   -- ------------------------------------- 1.3/24.0 MB 5.2 MB/s eta 0:00:05\n",
            "   ----- ---------------------------------- 3.1/24.0 MB 5.8 MB/s eta 0:00:04\n",
            "   ----- ---------------------------------- 3.4/24.0 MB 5.9 MB/s eta 0:00:04\n",
            "   --------- ------------------------------ 5.5/24.0 MB 6.0 MB/s eta 0:00:04\n",
            "   ----------- ---------------------------- 6.8/24.0 MB 5.9 MB/s eta 0:00:03\n",
            "   ------------- -------------------------- 8.1/24.0 MB 5.9 MB/s eta 0:00:03\n",
            "   --------------- ------------------------ 9.2/24.0 MB 5.8 MB/s eta 0:00:03\n",
            "   ---------------- ----------------------- 10.0/24.0 MB 5.6 MB/s eta 0:00:03\n",
            "   ------------------ --------------------- 11.0/24.0 MB 5.5 MB/s eta 0:00:03\n",
            "   ------------------- -------------------- 11.8/24.0 MB 5.4 MB/s eta 0:00:03\n",
            "   --------------------- ------------------ 12.8/24.0 MB 5.3 MB/s eta 0:00:03\n",
            "   ----------------------- ---------------- 13.9/24.0 MB 5.3 MB/s eta 0:00:02\n",
            "   ------------------------ --------------- 14.9/24.0 MB 5.2 MB/s eta 0:00:02\n",
            "   -------------------------- ------------- 16.0/24.0 MB 5.2 MB/s eta 0:00:02\n",
            "   ---------------------------- ----------- 17.0/24.0 MB 5.2 MB/s eta 0:00:02\n",
            "   ------------------------------ --------- 18.1/24.0 MB 5.2 MB/s eta 0:00:02\n",
            "   ------------------------------- -------- 19.1/24.0 MB 5.2 MB/s eta 0:00:01\n",
            "   --------------------------------- ------ 20.2/24.0 MB 5.1 MB/s eta 0:00:01\n",
            "   ----------------------------------- ---- 21.2/24.0 MB 5.1 MB/s eta 0:00:01\n",
            "   ------------------------------------ --- 22.0/24.0 MB 5.1 MB/s eta 0:00:01\n",
            "   -------------------------------------- - 23.1/24.0 MB 5.1 MB/s eta 0:00:01\n",
            "   -------------------------------------- - 23.3/24.0 MB 5.0 MB/s eta 0:00:01\n",
            "   ---------------------------------------  23.9/24.0 MB 4.9 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 24.0/24.0 MB 4.8 MB/s eta 0:00:00\n",
            "Downloading numpy-1.26.4-cp311-cp311-win_amd64.whl (15.8 MB)\n",
            "   ---------------------------------------- 0.0/15.8 MB ? eta -:--:--\n",
            "    --------------------------------------- 0.3/15.8 MB ? eta -:--:--\n",
            "   - -------------------------------------- 0.8/15.8 MB 2.0 MB/s eta 0:00:08\n",
            "   --- ------------------------------------ 1.3/15.8 MB 2.3 MB/s eta 0:00:07\n",
            "   ---- ----------------------------------- 1.8/15.8 MB 2.5 MB/s eta 0:00:06\n",
            "   ------ --------------------------------- 2.6/15.8 MB 2.6 MB/s eta 0:00:06\n",
            "   ------- -------------------------------- 3.1/15.8 MB 2.7 MB/s eta 0:00:05\n",
            "   --------- ------------------------------ 3.7/15.8 MB 2.7 MB/s eta 0:00:05\n",
            "   ----------- ---------------------------- 4.5/15.8 MB 2.8 MB/s eta 0:00:05\n",
            "   ------------- -------------------------- 5.2/15.8 MB 2.9 MB/s eta 0:00:04\n",
            "   -------------- ------------------------- 5.8/15.8 MB 2.9 MB/s eta 0:00:04\n",
            "   --------------- ------------------------ 6.3/15.8 MB 2.9 MB/s eta 0:00:04\n",
            "   ----------------- ---------------------- 7.1/15.8 MB 2.9 MB/s eta 0:00:04\n",
            "   ------------------- -------------------- 7.6/15.8 MB 2.9 MB/s eta 0:00:03\n",
            "   --------------------- ------------------ 8.4/15.8 MB 2.9 MB/s eta 0:00:03\n",
            "   ---------------------- ----------------- 8.9/15.8 MB 2.9 MB/s eta 0:00:03\n",
            "   ------------------------ --------------- 9.7/15.8 MB 3.0 MB/s eta 0:00:03\n",
            "   ------------------------- -------------- 10.0/15.8 MB 3.0 MB/s eta 0:00:02\n",
            "   --------------------------- ------------ 10.7/15.8 MB 2.9 MB/s eta 0:00:02\n",
            "   ---------------------------- ----------- 11.3/15.8 MB 2.9 MB/s eta 0:00:02\n",
            "   ----------------------------- ---------- 11.8/15.8 MB 2.9 MB/s eta 0:00:02\n",
            "   ------------------------------- -------- 12.3/15.8 MB 2.8 MB/s eta 0:00:02\n",
            "   -------------------------------- ------- 12.8/15.8 MB 2.8 MB/s eta 0:00:02\n",
            "   --------------------------------- ------ 13.4/15.8 MB 2.8 MB/s eta 0:00:01\n",
            "   ----------------------------------- ---- 13.9/15.8 MB 2.8 MB/s eta 0:00:01\n",
            "   ------------------------------------ --- 14.4/15.8 MB 2.8 MB/s eta 0:00:01\n",
            "   -------------------------------------- - 15.2/15.8 MB 2.8 MB/s eta 0:00:01\n",
            "   ---------------------------------------  15.7/15.8 MB 2.8 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 15.8/15.8 MB 2.8 MB/s eta 0:00:00\n",
            "Downloading scipy-1.13.1-cp311-cp311-win_amd64.whl (46.2 MB)\n",
            "   ---------------------------------------- 0.0/46.2 MB ? eta -:--:--\n",
            "   ---------------------------------------- 0.5/46.2 MB 2.4 MB/s eta 0:00:19\n",
            "    --------------------------------------- 1.0/46.2 MB 2.7 MB/s eta 0:00:17\n",
            "   - -------------------------------------- 1.6/46.2 MB 2.6 MB/s eta 0:00:18\n",
            "   - -------------------------------------- 2.1/46.2 MB 2.7 MB/s eta 0:00:17\n",
            "   -- ------------------------------------- 2.6/46.2 MB 2.6 MB/s eta 0:00:18\n",
            "   -- ------------------------------------- 3.1/46.2 MB 2.5 MB/s eta 0:00:18\n",
            "   -- ------------------------------------- 3.4/46.2 MB 2.5 MB/s eta 0:00:18\n",
            "   --- ------------------------------------ 3.9/46.2 MB 2.4 MB/s eta 0:00:18\n",
            "   --- ------------------------------------ 4.5/46.2 MB 2.4 MB/s eta 0:00:18\n",
            "   ---- ----------------------------------- 5.0/46.2 MB 2.4 MB/s eta 0:00:18\n",
            "   ---- ----------------------------------- 5.5/46.2 MB 2.4 MB/s eta 0:00:17\n",
            "   ----- ---------------------------------- 6.0/46.2 MB 2.4 MB/s eta 0:00:17\n",
            "   ----- ---------------------------------- 6.6/46.2 MB 2.4 MB/s eta 0:00:17\n",
            "   ------ --------------------------------- 7.1/46.2 MB 2.5 MB/s eta 0:00:16\n",
            "   ------ --------------------------------- 7.9/46.2 MB 2.5 MB/s eta 0:00:16\n",
            "   ------- -------------------------------- 8.1/46.2 MB 2.4 MB/s eta 0:00:16\n",
            "   ------- -------------------------------- 8.7/46.2 MB 2.4 MB/s eta 0:00:16\n",
            "   ------- -------------------------------- 8.9/46.2 MB 2.4 MB/s eta 0:00:16\n",
            "   -------- ------------------------------- 9.4/46.2 MB 2.4 MB/s eta 0:00:16\n",
            "   -------- ------------------------------- 9.7/46.2 MB 2.4 MB/s eta 0:00:16\n",
            "   -------- ------------------------------- 10.2/46.2 MB 2.3 MB/s eta 0:00:16\n",
            "   --------- ------------------------------ 10.7/46.2 MB 2.3 MB/s eta 0:00:16\n",
            "   --------- ------------------------------ 11.0/46.2 MB 2.3 MB/s eta 0:00:16\n",
            "   --------- ------------------------------ 11.5/46.2 MB 2.3 MB/s eta 0:00:16\n",
            "   ---------- ----------------------------- 11.8/46.2 MB 2.3 MB/s eta 0:00:16\n",
            "   ---------- ----------------------------- 12.3/46.2 MB 2.3 MB/s eta 0:00:16\n",
            "   ----------- ---------------------------- 12.8/46.2 MB 2.2 MB/s eta 0:00:15\n",
            "   ----------- ---------------------------- 13.1/46.2 MB 2.2 MB/s eta 0:00:15\n",
            "   ----------- ---------------------------- 13.6/46.2 MB 2.2 MB/s eta 0:00:15\n",
            "   ------------ --------------------------- 14.2/46.2 MB 2.2 MB/s eta 0:00:15\n",
            "   ------------ --------------------------- 14.4/46.2 MB 2.2 MB/s eta 0:00:15\n",
            "   ------------ --------------------------- 14.9/46.2 MB 2.2 MB/s eta 0:00:15\n",
            "   ------------- -------------------------- 15.5/46.2 MB 2.2 MB/s eta 0:00:14\n",
            "   ------------- -------------------------- 16.0/46.2 MB 2.2 MB/s eta 0:00:14\n",
            "   -------------- ------------------------- 16.3/46.2 MB 2.2 MB/s eta 0:00:14\n",
            "   -------------- ------------------------- 16.8/46.2 MB 2.2 MB/s eta 0:00:14\n",
            "   -------------- ------------------------- 17.3/46.2 MB 2.2 MB/s eta 0:00:14\n",
            "   --------------- ------------------------ 17.6/46.2 MB 2.2 MB/s eta 0:00:13\n",
            "   --------------- ------------------------ 18.1/46.2 MB 2.2 MB/s eta 0:00:13\n",
            "   ---------------- ----------------------- 18.6/46.2 MB 2.2 MB/s eta 0:00:13\n",
            "   ---------------- ----------------------- 19.1/46.2 MB 2.2 MB/s eta 0:00:13\n",
            "   ----------------- ---------------------- 19.7/46.2 MB 2.2 MB/s eta 0:00:13\n",
            "   ----------------- ---------------------- 20.2/46.2 MB 2.2 MB/s eta 0:00:12\n",
            "   ----------------- ---------------------- 20.4/46.2 MB 2.2 MB/s eta 0:00:12\n",
            "   ------------------ --------------------- 21.0/46.2 MB 2.2 MB/s eta 0:00:12\n",
            "   ------------------ --------------------- 21.5/46.2 MB 2.2 MB/s eta 0:00:12\n",
            "   ------------------- -------------------- 22.0/46.2 MB 2.2 MB/s eta 0:00:11\n",
            "   ------------------- -------------------- 22.5/46.2 MB 2.2 MB/s eta 0:00:11\n",
            "   ------------------- -------------------- 23.1/46.2 MB 2.2 MB/s eta 0:00:11\n",
            "   -------------------- ------------------- 23.6/46.2 MB 2.2 MB/s eta 0:00:11\n",
            "   -------------------- ------------------- 24.1/46.2 MB 2.2 MB/s eta 0:00:10\n",
            "   --------------------- ------------------ 24.6/46.2 MB 2.2 MB/s eta 0:00:10\n",
            "   --------------------- ------------------ 25.2/46.2 MB 2.3 MB/s eta 0:00:10\n",
            "   ---------------------- ----------------- 25.7/46.2 MB 2.3 MB/s eta 0:00:10\n",
            "   ---------------------- ----------------- 26.2/46.2 MB 2.3 MB/s eta 0:00:09\n",
            "   ----------------------- ---------------- 26.7/46.2 MB 2.3 MB/s eta 0:00:09\n",
            "   ----------------------- ---------------- 27.3/46.2 MB 2.3 MB/s eta 0:00:09\n",
            "   ------------------------ --------------- 27.8/46.2 MB 2.3 MB/s eta 0:00:09\n",
            "   ------------------------ --------------- 28.6/46.2 MB 2.3 MB/s eta 0:00:08\n",
            "   ------------------------- -------------- 29.1/46.2 MB 2.3 MB/s eta 0:00:08\n",
            "   ------------------------- -------------- 29.6/46.2 MB 2.3 MB/s eta 0:00:08\n",
            "   -------------------------- ------------- 30.4/46.2 MB 2.3 MB/s eta 0:00:07\n",
            "   --------------------------- ------------ 31.2/46.2 MB 2.3 MB/s eta 0:00:07\n",
            "   --------------------------- ------------ 31.7/46.2 MB 2.4 MB/s eta 0:00:07\n",
            "   ---------------------------- ----------- 32.5/46.2 MB 2.4 MB/s eta 0:00:06\n",
            "   ---------------------------- ----------- 33.3/46.2 MB 2.4 MB/s eta 0:00:06\n",
            "   ----------------------------- ---------- 34.1/46.2 MB 2.4 MB/s eta 0:00:06\n",
            "   ------------------------------ --------- 34.9/46.2 MB 2.4 MB/s eta 0:00:05\n",
            "   ------------------------------ --------- 35.4/46.2 MB 2.4 MB/s eta 0:00:05\n",
            "   ------------------------------- -------- 35.9/46.2 MB 2.4 MB/s eta 0:00:05\n",
            "   ------------------------------- -------- 36.4/46.2 MB 2.4 MB/s eta 0:00:05\n",
            "   -------------------------------- ------- 37.2/46.2 MB 2.4 MB/s eta 0:00:04\n",
            "   -------------------------------- ------- 37.7/46.2 MB 2.5 MB/s eta 0:00:04\n",
            "   --------------------------------- ------ 38.3/46.2 MB 2.4 MB/s eta 0:00:04\n",
            "   --------------------------------- ------ 38.8/46.2 MB 2.5 MB/s eta 0:00:04\n",
            "   ---------------------------------- ----- 39.3/46.2 MB 2.5 MB/s eta 0:00:03\n",
            "   ---------------------------------- ----- 39.8/46.2 MB 2.5 MB/s eta 0:00:03\n",
            "   ----------------------------------- ---- 40.6/46.2 MB 2.5 MB/s eta 0:00:03\n",
            "   ----------------------------------- ---- 41.2/46.2 MB 2.5 MB/s eta 0:00:03\n",
            "   ------------------------------------ --- 41.7/46.2 MB 2.5 MB/s eta 0:00:02\n",
            "   ------------------------------------ --- 42.5/46.2 MB 2.5 MB/s eta 0:00:02\n",
            "   ------------------------------------- -- 43.0/46.2 MB 2.5 MB/s eta 0:00:02\n",
            "   ------------------------------------- -- 43.8/46.2 MB 2.5 MB/s eta 0:00:01\n",
            "   -------------------------------------- - 44.3/46.2 MB 2.5 MB/s eta 0:00:01\n",
            "   ---------------------------------------  45.1/46.2 MB 2.5 MB/s eta 0:00:01\n",
            "   ---------------------------------------  45.6/46.2 MB 2.5 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 46.2/46.2 MB 2.5 MB/s eta 0:00:00\n",
            "Downloading smart_open-7.3.1-py3-none-any.whl (61 kB)\n",
            "Downloading wrapt-1.17.3-cp311-cp311-win_amd64.whl (38 kB)\n",
            "Installing collected packages: wrapt, numpy, smart-open, scipy, gensim\n",
            "\n",
            "   -------- ------------------------------- 1/5 [numpy]\n",
            "   -------- ------------------------------- 1/5 [numpy]\n",
            "   -------- ------------------------------- 1/5 [numpy]\n",
            "   -------- ------------------------------- 1/5 [numpy]\n",
            "   -------- ------------------------------- 1/5 [numpy]\n",
            "   -------- ------------------------------- 1/5 [numpy]\n",
            "   -------- ------------------------------- 1/5 [numpy]\n",
            "   -------- ------------------------------- 1/5 [numpy]\n",
            "   -------- ------------------------------- 1/5 [numpy]\n",
            "   -------- ------------------------------- 1/5 [numpy]\n",
            "   -------- ------------------------------- 1/5 [numpy]\n",
            "   -------- ------------------------------- 1/5 [numpy]\n",
            "   -------- ------------------------------- 1/5 [numpy]\n",
            "   -------- ------------------------------- 1/5 [numpy]\n",
            "   -------- ------------------------------- 1/5 [numpy]\n",
            "   -------- ------------------------------- 1/5 [numpy]\n",
            "   -------- ------------------------------- 1/5 [numpy]\n",
            "   ------------------------ --------------- 3/5 [scipy]\n",
            "   ------------------------ --------------- 3/5 [scipy]\n",
            "   ------------------------ --------------- 3/5 [scipy]\n",
            "   ------------------------ --------------- 3/5 [scipy]\n",
            "   ------------------------ --------------- 3/5 [scipy]\n",
            "   ------------------------ --------------- 3/5 [scipy]\n",
            "   ------------------------ --------------- 3/5 [scipy]\n",
            "   ------------------------ --------------- 3/5 [scipy]\n",
            "   ------------------------ --------------- 3/5 [scipy]\n",
            "   ------------------------ --------------- 3/5 [scipy]\n",
            "   ------------------------ --------------- 3/5 [scipy]\n",
            "   ------------------------ --------------- 3/5 [scipy]\n",
            "   ------------------------ --------------- 3/5 [scipy]\n",
            "   ------------------------ --------------- 3/5 [scipy]\n",
            "   ------------------------ --------------- 3/5 [scipy]\n",
            "   ------------------------ --------------- 3/5 [scipy]\n",
            "   ------------------------ --------------- 3/5 [scipy]\n",
            "   ------------------------ --------------- 3/5 [scipy]\n",
            "   ------------------------ --------------- 3/5 [scipy]\n",
            "   ------------------------ --------------- 3/5 [scipy]\n",
            "   ------------------------ --------------- 3/5 [scipy]\n",
            "   ------------------------ --------------- 3/5 [scipy]\n",
            "   ------------------------ --------------- 3/5 [scipy]\n",
            "   ------------------------ --------------- 3/5 [scipy]\n",
            "   ------------------------ --------------- 3/5 [scipy]\n",
            "   ------------------------ --------------- 3/5 [scipy]\n",
            "   ------------------------ --------------- 3/5 [scipy]\n",
            "   ------------------------ --------------- 3/5 [scipy]\n",
            "   ------------------------ --------------- 3/5 [scipy]\n",
            "   ------------------------ --------------- 3/5 [scipy]\n",
            "   ------------------------ --------------- 3/5 [scipy]\n",
            "   ------------------------ --------------- 3/5 [scipy]\n",
            "   -------------------------------- ------- 4/5 [gensim]\n",
            "   -------------------------------- ------- 4/5 [gensim]\n",
            "   -------------------------------- ------- 4/5 [gensim]\n",
            "   -------------------------------- ------- 4/5 [gensim]\n",
            "   -------------------------------- ------- 4/5 [gensim]\n",
            "   ---------------------------------------- 5/5 [gensim]\n",
            "\n",
            "Successfully installed gensim-4.3.3 numpy-1.26.4 scipy-1.13.1 smart-open-7.3.1 wrapt-1.17.3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 25.1.1 -> 25.2\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "!pip3 install gensim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "O8YJTOYv6j0s"
      },
      "outputs": [],
      "source": [
        "from gensim.models.keyedvectors import KeyedVectors\n",
        "wv_embeddings = KeyedVectors.load_word2vec_format(r\"C:\\Project\\DeepLearningSchool\\NLP\\SO_vectors_200.bindownload=1\", binary=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "200"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(wv_embeddings[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1787145"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(wv_embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[('problem', 0.8884832262992859), ('issues', 0.840576708316803), ('problems', 0.7842557430267334), ('bug', 0.6874933838844299), ('isssue', 0.6070330739021301), ('issue-', 0.606260359287262), ('woes', 0.60285884141922), ('issuse', 0.5781072378158569), ('isse', 0.5734156370162964), ('weirdness', 0.5670750737190247)]\n"
          ]
        }
      ],
      "source": [
        "print(list(wv_embeddings.most_similar(100)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['use', 'code', 'using', 'like', 'will', 'want', 'need', 'get', 'file', 'one', 'just', 'data', 'way', '1', 'also', 'function', 'problem', 'error', '-', 'example', '2', 'class', 'work', 'value', 'method', 'first', 'set', 'see', 'following', '0', 'user', 'make', 'new', 'add', 'know', 'try', 'time', 'something', 'http', 'trying', 'create', 'object', 'now', 'page', 'server', 'string', 'help', 'app', 'list', 'table']\n"
          ]
        }
      ],
      "source": [
        "print(list(wv_embeddings.key_to_index.keys())[:50])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aIcT_g-C6j1E"
      },
      "source": [
        "#### Как пользоваться этими векторами?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DWO5SPDY6j1G"
      },
      "source": [
        "Посмотрим на примере одного слова, что из себя представляет embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "KeSBlQfk6j1J",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "float32 (200,)\n"
          ]
        }
      ],
      "source": [
        "word = 'cat'\n",
        "if word in wv_embeddings:\n",
        "    print(wv_embeddings[word].dtype, wv_embeddings[word].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "T4Eq-D1qxpMJ"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Num of words: 1787145\n"
          ]
        }
      ],
      "source": [
        "print(f\"Num of words: {len(wv_embeddings.index_to_key)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZT6NTCys6j1Q"
      },
      "source": [
        "Найдем наиболее близкие слова к слову `dog`:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n08z2PjMwC5o"
      },
      "source": [
        "#### ***Вопрос 1:***\n",
        "* Входит ли слово `cat` в топ-5 близких слов к слову `dog`? Какое место оно занимает?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('animal', 0.8564180135726929),\n",
              " ('dogs', 0.7880866527557373),\n",
              " ('mammal', 0.7623804211616516),\n",
              " ('cats', 0.7621253728866577),\n",
              " ('animals', 0.760793924331665),\n",
              " ('feline', 0.7392398715019226),\n",
              " ('bird', 0.7315488457679749),\n",
              " ('animal1', 0.7219215631484985),\n",
              " ('doggy', 0.7213349342346191),\n",
              " ('labrador', 0.7209131717681885)]"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "wv_embeddings.most_similar(\"dog\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Wu7O43AY5jH"
      },
      "source": [
        "***Ваш ответ:*** 'cat' не входит в топ-5 ближайших слов к 'dog'. Но слово `cats` входит (4 место)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ai48-5vv6j1d"
      },
      "source": [
        "### Векторные представления текста\n",
        "\n",
        "Перейдем от векторных представлений отдельных слов к векторным представлениям вопросов, как к **среднему** векторов всех слов в вопросе. Если для какого-то слова нет предобученного вектора, то его нужно пропустить. Если вопрос не содержит ни одного известного слова, то нужно вернуть нулевой вектор."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "EhNuxBJd6j1f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Hello', 'my', '1', 'friend']"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import numpy as np\n",
        "import re\n",
        "# you can use your tokenizer\n",
        "# for example, from nltk.tokenize import WordPunctTokenizer\n",
        "class MyTokenizer:\n",
        "    def __init__(self):\n",
        "        pass\n",
        "    def tokenize(self, text):\n",
        "        return re.findall('\\w+', text)\n",
        "tokenizer = MyTokenizer()\n",
        "tokenizer.tokenize(\"Hello, my 1.friend\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "YHcvu6186j1m"
      },
      "outputs": [],
      "source": [
        "def question_to_vec(question, embeddings, tokenizer, dim=200):\n",
        "    \"\"\"\n",
        "        question: строка\n",
        "        embeddings: наше векторное представление\n",
        "        dim: размер любого вектора в нашем представлении\n",
        "\n",
        "        return: векторное представление для вопроса\n",
        "    \"\"\"\n",
        "    vec_words = []\n",
        "\n",
        "    for word in tokenizer.tokenize(question):\n",
        "        if word in embeddings:\n",
        "            vec_words.append(embeddings[word])\n",
        "\n",
        "    return np.mean(vec_words, axis=0) if vec_words else np.zeros(dim)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Проверка"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "v1 = question_to_vec(\"cats wolf\", wv_embeddings, tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "v2 = question_to_vec(\"a\", wv_embeddings, tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "v1.shape == v2.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u5Q_4j7r6j1u"
      },
      "source": [
        "Теперь у нас есть метод для создания векторного представления любого предложения."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EsJSNkhm6j1y"
      },
      "source": [
        "#### ***Вопрос 2:***\n",
        "\n",
        "* Какая третья (с индексом 2) компонента вектора предложения `I love neural networks` (округлите до 2 знаков после запятой)?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "a62r11cT6j10",
        "scrolled": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "-1.29"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Предложение\n",
        "question = \"I love neural networks\"\n",
        "\n",
        "np.round_(question_to_vec(question, wv_embeddings, tokenizer)[2], 2)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wGNTG18dY73d"
      },
      "source": [
        "-1.29"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y60z4t6W6j16"
      },
      "source": [
        "### Оценка близости текстов\n",
        "\n",
        "Представим, что мы используем идеальные векторные представления слов. Тогда косинусное расстояние между дублирующими предложениями должно быть меньше, чем между случайно взятыми предложениями.\n",
        "\n",
        "Сгенерируем для каждого из $N$ вопросов $R$ случайных отрицательных примеров и примешаем к ним также настоящие дубликаты. Для каждого вопроса будем ранжировать с помощью нашей модели $R + 1$ примеров и смотреть на позицию дубликата. Мы хотим, чтобы дубликат был первым в ранжированном списке.\n",
        "\n",
        "#### Hits@K\n",
        "Первой простой метрикой будет количество корректных попаданий для какого-то $K$:\n",
        "$$ \\text{Hits@K} = \\frac{1}{N}\\sum_{i=1}^N \\, [rank\\_q_i^{'} \\le K],$$\n",
        "* $$\\begin{equation*}\n",
        "[x < 0 ] \\equiv\n",
        " \\begin{cases}\n",
        "   1, &x < 0 \\\\\n",
        "   0, &x \\qeq 0\n",
        " \\end{cases}\n",
        "\\end{equation*}$$ - индикаторная функция\n",
        "* $q_i$ - $i$-ый вопрос\n",
        "* $q_i^{'}$ - его дубликат\n",
        "* $rank\\_q_i^{'}$ - позиция дубликата в ранжированном списке ближайших предложений для вопроса $q_i$.\n",
        "\n",
        "Hits@K  измеряет долю вопросов, для которых правильный ответ попал в топ-K позиций среди отранжированных кандидатов.\n",
        "\n",
        "#### DCG@K\n",
        "Второй метрикой будет упрощенная DCG метрика, учитывающая порядок элементов в списке путем домножения релевантности элемента на вес равный обратному логарифму номера позиции::\n",
        "$$ \\text{DCG@K} = \\frac{1}{N} \\sum_{i=1}^N\\frac{1}{\\log_2(1+rank\\_q_i^{'})}\\cdot[rank\\_q_i^{'} \\le K],$$\n",
        "С такой метрикой модель штрафуется за большой ранк корректного ответа.\n",
        "\n",
        "DCG@K  измеряет качество ранжирования, учитывая не только факт наличия правильного ответа в топ-K, но и ***его точную позицию***."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_tFemBkP6j1-"
      },
      "source": [
        "<img src='https://hsto.org/files/1c5/edf/dee/1c5edfdeebce4b71a86bdf986d9f88f2.jpg' width=400, height=200>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0sUSxk866j1_"
      },
      "source": [
        "#### Пример оценок\n",
        "\n",
        "Вычислим описанные выше метрики для игрушечного примера.\n",
        "Пусть\n",
        "* $N = 1$, $R = 3$\n",
        "* <font color='green'>\"Что такое python?\"</font> - вопрос $q_1$\n",
        "* <font color='red'>\"Что такое язык python?\"</font> - его дубликат $q_i^{'}$\n",
        "\n",
        "Пусть модель выдала следующий ранжированный список кандидатов:\n",
        "\n",
        "1. \"Как изучить с++?\"\n",
        "2. <font color='red'>\"Что такое язык python?\"</font>\n",
        "3. \"Хочу учить Java\"\n",
        "4. \"Не понимаю Tensorflow\"\n",
        "\n",
        "$\\Rightarrow rank\\_q_i^{'} = 2$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-XXCbN3uUiHU"
      },
      "source": [
        "Вычислим метрику *Hits@K* для *K = 1, 4*:\n",
        "\n",
        "- [K = 1] $\\text{Hits@1} =  [rank\\_q_i^{'} \\le 1]$\n",
        "\n",
        "Проверяем условие $ \\text{rank}_{q'_1} \\leq 1 $: ***условие неверно***.\n",
        "\n",
        "Следовательно, $[\\text{rank}_{q'_1} \\leq 1] = 0$.\n",
        "\n",
        "- [K = 4] $\\text{Hits@4} =  [rank\\_q_i^{'} \\le 4] = 1$\n",
        "\n",
        "Проверяем условие $ \\text{rank}_{q'_1} \\leq 4 $: ***условие верно***."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ya9gf-dvVGmm"
      },
      "source": [
        "Вычислим метрику *DCG@K* для *K = 1, 4*:\n",
        "- [K = 1] $\\text{DCG@1} = \\frac{1}{\\log_2(1+2)}\\cdot[2 \\le 1] = 0$\n",
        "- [K = 4] $\\text{DCG@4} = \\frac{1}{\\log_2(1+2)}\\cdot[2 \\le 4] = \\frac{1}{\\log_2{3}}$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B4L6HJJC6j2B"
      },
      "source": [
        "#### ***Вопрос 3***:\n",
        "* Вычислите `DCG@10`, если $rank\\_q_i^{'} = 9$(округлите до одного знака после запятой)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.3010299956639812"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import math\n",
        "\n",
        "\n",
        "def dcg(rank_q_i, k):\n",
        "    if rank_q_i <= k:\n",
        "        return 1/(math.log2(1 + rank_q_i))\n",
        "    return 0\n",
        "\n",
        "dcg(9, 10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Ответ: 0,3**\n",
        "\n",
        "\n",
        "Можно заметить, что если rank_q_i < k_1, то повышение k_1 не привдет к изменению."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hM1PtUq3haNS"
      },
      "source": [
        "#### Более сложный пример оценок\n",
        "\n",
        "Рассмотрим пример с $ N > 1 $, где $ N = 3 $ (три вопроса) и для каждого вопроса заданы позиции их дубликатов. Вычислим метрики **Hits@K** для разных значений $ K $.\n",
        "\n",
        "---\n",
        "\n",
        "- $ N = 3 $: Три вопроса ($ q_1, q_2, q_3 $).\n",
        "- Для каждого вопроса известна позиция его дубликата ($ \\text{rank}_{q'_i} $):\n",
        "  - $ \\text{rank}_{q'_1} = 2 $,\n",
        "  - $ \\text{rank}_{q'_2} = 5 $,\n",
        "  - $ \\text{rank}_{q'_3} = 1 $.\n",
        "\n",
        "Мы будем вычислять **Hits@K** для $ K = 1, 5 $.\n",
        "\n",
        "---\n",
        "\n",
        "**Для $ K = 1 $:**\n",
        "\n",
        "Подставим значения:\n",
        "$$\n",
        "\\text{Hits@1} = \\frac{1}{3} \\cdot \\left( [\\text{rank}_{q'_1} \\leq 1] + [\\text{rank}_{q'_2} \\leq 1] + [\\text{rank}_{q'_3} \\leq 1] \\right).\n",
        "$$\n",
        "\n",
        "Проверяем условие $ \\text{rank}_{q'_i} \\leq 1 $ для каждого вопроса:\n",
        "- $ \\text{rank}_{q'_1} = 2 $ → $ 2 \\not\\leq 1 $ → $ 0 $,\n",
        "- $ \\text{rank}_{q'_2} = 5 $ → $ 5 \\not\\leq 1 $ → $ 0 $,\n",
        "- $ \\text{rank}_{q'_3} = 1 $ → $ 1 \\leq 1 $ → $ 1 $.\n",
        "\n",
        "Сумма:\n",
        "$$\n",
        "\\text{Hits@1} = \\frac{1}{3} \\cdot (0 + 0 + 1) = \\frac{1}{3}.\n",
        "$$\n",
        "\n",
        "$$\n",
        "\\boxed{\\text{Hits@1} = \\frac{1}{3}}.\n",
        "$$\n",
        "\n",
        "---\n",
        "\n",
        "**Для $ K = 5 $:**\n",
        "\n",
        "Подставим значения:\n",
        "$$\n",
        "\\text{Hits@5} = \\frac{1}{3} \\cdot \\left( [\\text{rank}_{q'_1} \\leq 5] + [\\text{rank}_{q'_2} \\leq 5] + [\\text{rank}_{q'_3} \\leq 5] \\right).\n",
        "$$\n",
        "\n",
        "Проверяем условие $ \\text{rank}_{q'_i} \\leq 5 $ для каждого вопроса:\n",
        "- $ \\text{rank}_{q'_1} = 2 $ → $ 2 \\leq 5 $ → $ 1 $,\n",
        "- $ \\text{rank}_{q'_2} = 5 $ → $ 5 \\leq 5 $ → $ 1 $,\n",
        "- $ \\text{rank}_{q'_3} = 1 $ → $ 1 \\leq 5 $ → $ 1 $.\n",
        "\n",
        "Сумма:\n",
        "$$\n",
        "\\text{Hits@5} = \\frac{1}{3} \\cdot (1 + 1 + 1) = 1.\n",
        "$$\n",
        "\n",
        "$$\n",
        "\\boxed{\\text{Hits@5} = 1}.\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ngfvO7JsqROf"
      },
      "source": [
        "Теперь вычислим метрику **DCG@K** для того же примера, где $ N = 3 $ (три вопроса), и для каждого вопроса известна позиция его дубликата ($ \\text{rank}_{q'_i} $):\n",
        "\n",
        "- $ \\text{rank}_{q'_1} = 2 $,\n",
        "- $ \\text{rank}_{q'_2} = 5 $,\n",
        "- $ \\text{rank}_{q'_3} = 1 $.\n",
        "\n",
        "Мы будем вычислять **DCG@K** для $ K = 1, 5 $.\n",
        "\n",
        "---\n",
        "**Для $ K = 1 $:**\n",
        "Подставим значения:\n",
        "$$\n",
        "\\text{DCG@1} = \\frac{1}{3} \\cdot \\left( \\frac{1}{\\log_2(1 + \\text{rank}_{q'_1})} \\cdot [\\text{rank}_{q'_1} \\leq 1] + \\frac{1}{\\log_2(1 + \\text{rank}_{q'_2})} \\cdot [\\text{rank}_{q'_2} \\leq 1] + \\frac{1}{\\log_2(1 + \\text{rank}_{q'_3})} \\cdot [\\text{rank}_{q'_3} \\leq 1] \\right).\n",
        "$$\n",
        "\n",
        "Проверяем условие $ \\text{rank}_{q'_i} \\leq 1 $ для каждого вопроса:\n",
        "- $ \\text{rank}_{q'_1} = 2 $ → $ 2 \\not\\leq 1 $ → $ 0 $,\n",
        "- $ \\text{rank}_{q'_2} = 5 $ → $ 5 \\not\\leq 1 $ → $ 0 $,\n",
        "- $ \\text{rank}_{q'_3} = 1 $ → $ 1 \\leq 1 $ → $ 1 $.\n",
        "\n",
        "Сумма:\n",
        "$$\n",
        "\\text{DCG@1} = \\frac{1}{3} \\cdot (0 + 0 + 1) = \\frac{1}{3}.\n",
        "$$\n",
        "$$\n",
        "\\boxed{\\text{DCG@1} = \\frac{1}{3}}.\n",
        "$$\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "**Для $ K = 5 $:**\n",
        "Подставим значения:\n",
        "$$\n",
        "\\text{DCG@5} = \\frac{1}{3} \\cdot \\left( \\frac{1}{\\log_2(1 + \\text{rank}_{q'_1})} \\cdot [\\text{rank}_{q'_1} \\leq 5] + \\frac{1}{\\log_2(1 + \\text{rank}_{q'_2})} \\cdot [\\text{rank}_{q'_2} \\leq 5] + \\frac{1}{\\log_2(1 + \\text{rank}_{q'_3})} \\cdot [\\text{rank}_{q'_3} \\leq 5] \\right).\n",
        "$$\n",
        "\n",
        "Проверяем условие $ \\text{rank}_{q'_i} \\leq 5 $ для каждого вопроса:\n",
        "- $ \\text{rank}_{q'_1} = 2 $ → $ 2 \\leq 5 $ → $ 1 $,\n",
        "- $ \\text{rank}_{q'_2} = 5 $ → $ 5 \\leq 5 $ → $ 1 $,\n",
        "- $ \\text{rank}_{q'_3} = 1 $ → $ 1 \\leq 5 $ → $ 1 $.\n",
        "\n",
        "Сумма:\n",
        "$$\n",
        "\\text{DCG@5} = \\frac{1}{3} \\cdot (0.631 + 0.387 + 1) = \\frac{1}{3} \\cdot 2.018 \\approx 0.673.\n",
        "$$\n",
        "\n",
        "$$\n",
        "\\boxed{\\text{DCG@5} \\approx 0.673}.\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eHCnH-jw6j18"
      },
      "source": [
        "#### ***Вопрос 4:***\n",
        "* Найдите максимум `Hits@47 - DCG@1`?\n",
        "\n",
        "Надо, чтобы Hits@47 -> max\n",
        "И, чтобы DCG@1 -> min\n",
        "\n",
        "Hits@47 стремится к максимум когда N -> min, а rank_q <= 47. Это от 1 до 47.\n",
        "\n",
        "DCG@1 стремится к минимуму, когда rank_q > k. Это 0.\n",
        "\n",
        "Получается максимум при rank_q равным от 2 до 47. Ответ 1\n",
        "\n",
        "Рассмотри для произвольного N > 0:\n",
        "\n",
        "Для DSG@1 важно, чтобы любое rank_q > k. Тогда все равно 0.\n",
        "\n",
        "Для Hits@47 -> будет к максимален, когда каждый rank_q Будет в это диапозоне от 1 до 47. Причем, заполнение должно идти. Анологично максимум равен 1. так как всего $\\frac{1}{N} * \\sum_{i=1}^{N}[rankq_i <= k] = \\frac{1}{N} * N$. Если все rank_q в пределах от 1 до 47. Но нам нельзя занимать 1 место иначе, тогда DCG@1 станет не нулевым. Тогда для этого случая получаем следующее.\n",
        "\n",
        "ОТВЕТ:\n",
        "\n",
        "Если $ N \\in [1; 46]$, то максимум равен 1.\n",
        "\n",
        "Если $ N \\in [47; +\\inf) $, то максимум $ \\frac{1}{N} * (N - 1)$\n",
        "\n",
        "\n",
        "Скорее всего предлагается N = 1, то  ответ 1\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J5xWOORI6j2F"
      },
      "source": [
        "### HITS\\_COUNT и DCG\\_SCORE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I1q9WQOx6j2H"
      },
      "source": [
        "Каждая функция имеет два аргумента: $dup\\_ranks$ и $k$.\n",
        "\n",
        "$dup\\_ranks$ является списком, который содержит рейтинги дубликатов (их позиции в ранжированном списке).\n",
        "\n",
        "К примеру для <font color='red'>\"Что такое язык python?\"</font> $dup\\_ranks = [2]$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "F5VwySUB6j2J"
      },
      "outputs": [],
      "source": [
        "def hits_count(dup_ranks, k):\n",
        "    \"\"\"\n",
        "        dup_ranks: list индексов дубликатов\n",
        "        k: пороговое значение для ранга\n",
        "        result: вернуть Hits@k\n",
        "    \"\"\"\n",
        "    # Подсчитываем количество дубликатов, чей ранг <= k\n",
        "    '''your code'''\n",
        "    s = 0\n",
        "    for i in dup_ranks:\n",
        "        if i <= k:\n",
        "            s+=1\n",
        "\n",
        "    return s/len(dup_ranks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "vSjm_5eWYVYI"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hits@1 = 0.0\n",
            "Hits@4 = 1.0\n"
          ]
        }
      ],
      "source": [
        "dup_ranks = [2]\n",
        "\n",
        "k = 1\n",
        "hits_value = hits_count(dup_ranks, k)\n",
        "print(f\"Hits@1 = {hits_value}\")\n",
        "\n",
        "k = 4\n",
        "hits_value = hits_count(dup_ranks, k)\n",
        "print(f\"Hits@4 = {hits_value}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "82hQaxCH6j2R"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "\n",
        "def dcg_score(dup_ranks, k):\n",
        "    \"\"\"\n",
        "        dup_ranks: list индексов дубликатов\n",
        "        k: пороговое значение для ранга\n",
        "        result: вернуть DCG@k\n",
        "    \"\"\"\n",
        "    s = 0\n",
        "    for i in dup_ranks:\n",
        "        if i <= k:\n",
        "            s += 1/math.log2((i+1))\n",
        "\n",
        "    return s/len(dup_ranks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "OJYsEdx-amB4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DCG@1 = 0.000\n",
            "DCG@10 = 0.631\n"
          ]
        }
      ],
      "source": [
        "# Пример списка позиций дубликатов\n",
        "dup_ranks = [2]\n",
        "\n",
        "# Вычисляем DCG@1\n",
        "dcg_value = dcg_score(dup_ranks, k=1)\n",
        "print(f\"DCG@1 = {dcg_value:.3f}\")\n",
        "\n",
        "# Вычисляем DCG@4\n",
        "dcg_value = dcg_score(dup_ranks, k=4)\n",
        "print(f\"DCG@10 = {dcg_value:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PcwHeXN26j2Y"
      },
      "source": [
        "Протестируем функции. Пусть $N = 1$, то есть один эксперимент. Будем искать копию вопроса и оценивать метрики."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pandas\n",
            "  Downloading pandas-2.3.2-cp311-cp311-win_amd64.whl.metadata (19 kB)\n",
            "Requirement already satisfied: numpy>=1.23.2 in c:\\project\\deeplearningschool\\.venv\\lib\\site-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\project\\deeplearningschool\\.venv\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
            "Collecting pytz>=2020.1 (from pandas)\n",
            "  Downloading pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Collecting tzdata>=2022.7 (from pandas)\n",
            "  Downloading tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: six>=1.5 in c:\\project\\deeplearningschool\\.venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Downloading pandas-2.3.2-cp311-cp311-win_amd64.whl (11.3 MB)\n",
            "   ---------------------------------------- 0.0/11.3 MB ? eta -:--:--\n",
            "   ---------------------------------------- 0.0/11.3 MB ? eta -:--:--\n",
            "    --------------------------------------- 0.3/11.3 MB ? eta -:--:--\n",
            "    --------------------------------------- 0.3/11.3 MB ? eta -:--:--\n",
            "   - -------------------------------------- 0.5/11.3 MB 932.9 kB/s eta 0:00:12\n",
            "   -- ------------------------------------- 0.8/11.3 MB 1.0 MB/s eta 0:00:11\n",
            "   ---- ----------------------------------- 1.3/11.3 MB 1.2 MB/s eta 0:00:09\n",
            "   ----- ---------------------------------- 1.6/11.3 MB 1.3 MB/s eta 0:00:08\n",
            "   ------- -------------------------------- 2.1/11.3 MB 1.4 MB/s eta 0:00:07\n",
            "   -------- ------------------------------- 2.4/11.3 MB 1.5 MB/s eta 0:00:07\n",
            "   ---------- ----------------------------- 2.9/11.3 MB 1.6 MB/s eta 0:00:06\n",
            "   ------------ --------------------------- 3.4/11.3 MB 1.7 MB/s eta 0:00:05\n",
            "   -------------- ------------------------- 4.2/11.3 MB 1.9 MB/s eta 0:00:04\n",
            "   ----------------- ---------------------- 5.0/11.3 MB 2.0 MB/s eta 0:00:04\n",
            "   -------------------- ------------------- 5.8/11.3 MB 2.2 MB/s eta 0:00:03\n",
            "   ------------------------ --------------- 6.8/11.3 MB 2.4 MB/s eta 0:00:02\n",
            "   --------------------------- ------------ 7.9/11.3 MB 2.6 MB/s eta 0:00:02\n",
            "   ------------------------------- -------- 8.9/11.3 MB 2.7 MB/s eta 0:00:01\n",
            "   ------------------------------------ --- 10.2/11.3 MB 3.0 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 11.3/11.3 MB 3.1 MB/s eta 0:00:00\n",
            "Downloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
            "Downloading tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
            "Installing collected packages: pytz, tzdata, pandas\n",
            "\n",
            "   ---------------------------------------- 0/3 [pytz]\n",
            "   ---------------------------------------- 0/3 [pytz]\n",
            "   ------------- -------------------------- 1/3 [tzdata]\n",
            "   ------------- -------------------------- 1/3 [tzdata]\n",
            "   -------------------------- ------------- 2/3 [pandas]\n",
            "   -------------------------- ------------- 2/3 [pandas]\n",
            "   -------------------------- ------------- 2/3 [pandas]\n",
            "   -------------------------- ------------- 2/3 [pandas]\n",
            "   -------------------------- ------------- 2/3 [pandas]\n",
            "   -------------------------- ------------- 2/3 [pandas]\n",
            "   -------------------------- ------------- 2/3 [pandas]\n",
            "   -------------------------- ------------- 2/3 [pandas]\n",
            "   -------------------------- ------------- 2/3 [pandas]\n",
            "   -------------------------- ------------- 2/3 [pandas]\n",
            "   -------------------------- ------------- 2/3 [pandas]\n",
            "   -------------------------- ------------- 2/3 [pandas]\n",
            "   -------------------------- ------------- 2/3 [pandas]\n",
            "   -------------------------- ------------- 2/3 [pandas]\n",
            "   -------------------------- ------------- 2/3 [pandas]\n",
            "   -------------------------- ------------- 2/3 [pandas]\n",
            "   -------------------------- ------------- 2/3 [pandas]\n",
            "   -------------------------- ------------- 2/3 [pandas]\n",
            "   -------------------------- ------------- 2/3 [pandas]\n",
            "   -------------------------- ------------- 2/3 [pandas]\n",
            "   -------------------------- ------------- 2/3 [pandas]\n",
            "   -------------------------- ------------- 2/3 [pandas]\n",
            "   -------------------------- ------------- 2/3 [pandas]\n",
            "   -------------------------- ------------- 2/3 [pandas]\n",
            "   -------------------------- ------------- 2/3 [pandas]\n",
            "   -------------------------- ------------- 2/3 [pandas]\n",
            "   -------------------------- ------------- 2/3 [pandas]\n",
            "   -------------------------- ------------- 2/3 [pandas]\n",
            "   -------------------------- ------------- 2/3 [pandas]\n",
            "   -------------------------- ------------- 2/3 [pandas]\n",
            "   -------------------------- ------------- 2/3 [pandas]\n",
            "   -------------------------- ------------- 2/3 [pandas]\n",
            "   -------------------------- ------------- 2/3 [pandas]\n",
            "   -------------------------- ------------- 2/3 [pandas]\n",
            "   -------------------------- ------------- 2/3 [pandas]\n",
            "   -------------------------- ------------- 2/3 [pandas]\n",
            "   -------------------------- ------------- 2/3 [pandas]\n",
            "   -------------------------- ------------- 2/3 [pandas]\n",
            "   -------------------------- ------------- 2/3 [pandas]\n",
            "   -------------------------- ------------- 2/3 [pandas]\n",
            "   -------------------------- ------------- 2/3 [pandas]\n",
            "   ---------------------------------------- 3/3 [pandas]\n",
            "\n",
            "Successfully installed pandas-2.3.2 pytz-2025.2 tzdata-2025.2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 25.1.1 -> 25.2\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "!pip3 install pandas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "fjISmOEW6j2h"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "gLa_Wqfh6j2m"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ваш ответ HIT: [0.0, 1.0, 1.0, 1.0]\n",
            "Ваш ответ DCG: [0.0, 0.63093, 0.63093, 0.63093]\n"
          ]
        }
      ],
      "source": [
        "copy_answers = [\"How does the catch keyword determine the type of exception that was thrown\",]\n",
        "\n",
        "# наши кандидаты\n",
        "candidates_ranking = [[\"How Can I Make These Links Rotate in PHP\",\n",
        "                       \"How does the catch keyword determine the type of exception that was thrown\",\n",
        "                       \"NSLog array description not memory address\",\n",
        "                       \"PECL_HTTP not recognised php ubuntu\"],]\n",
        "\n",
        "# dup_ranks — позиции наших копий, так как эксперимент один, то этот массив длины 1\n",
        "dup_ranks = [2]\n",
        "\n",
        "# вычисляем метрику для разных k\n",
        "print('Ваш ответ HIT:', [hits_count(dup_ranks, k) for k in range(1, 5)])\n",
        "print('Ваш ответ DCG:', [round(dcg_score(dup_ranks, k), 5) for k in range(1, 5)])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MoHC3YoQ6j2t"
      },
      "source": [
        "У вас должно получиться"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "id": "B0NFWq4f6j2u",
        "outputId": "4d70f590-9924-4b50-d400-cdbf43edf093",
        "scrolled": true
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>HITS</th>\n",
              "      <td>0</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>1.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DCG</th>\n",
              "      <td>0</td>\n",
              "      <td>0.63093</td>\n",
              "      <td>0.63093</td>\n",
              "      <td>0.63093</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      1        2        3        4\n",
              "HITS  0  1.00000  1.00000  1.00000\n",
              "DCG   0  0.63093  0.63093  0.63093"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# correct_answers - метрика для разных k\n",
        "correct_answers = pd.DataFrame([[0, 1, 1, 1], [0, 1 / (np.log2(3)), 1 / (np.log2(3)), 1 / (np.log2(3))]],\n",
        "                               index=['HITS', 'DCG'], columns=range(1,5))\n",
        "correct_answers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tHZqgDTo6j0i"
      },
      "source": [
        "### Данные\n",
        "[arxiv link](https://drive.google.com/file/d/1QqT4D0EoqJTy7v9VrNCYD-m964XZFR7_/edit)\n",
        "\n",
        "`train.tsv` - выборка для обучения.<br> В каждой строке через табуляцию записаны: **<вопрос>, <похожий вопрос>**\n",
        "\n",
        "`validation.tsv` - тестовая выборка.<br> В каждой строке через табуляцию записаны: **<вопрос>, <похожий вопрос>, <отрицательный пример 1>, <отрицательный пример 2>, ...**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jKVK2lDGvrIe",
        "outputId": "97ec0599-63f2-41dd-faf3-7a513d27e325"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Archive:  /home/devoloper/projects/DeepLearningSchool/NLP/some_data/stackoverflow_similar_questions.zip\n",
            "   creating: data/\n",
            "  inflating: data/.DS_Store          \n",
            "   creating: __MACOSX/\n",
            "   creating: __MACOSX/data/\n",
            "  inflating: __MACOSX/data/._.DS_Store  \n",
            "  inflating: data/train.tsv          \n",
            "  inflating: data/validation.tsv     \n"
          ]
        }
      ],
      "source": [
        "!unzip \"/home/devoloper/projects/DeepLearningSchool/NLP/some_data/stackoverflow_similar_questions.zip\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hil2UsUG6j22"
      },
      "source": [
        "Считайте данные."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "B4EBho8s6j26"
      },
      "outputs": [],
      "source": [
        "def read_corpus(filename):\n",
        "    data = []\n",
        "    with open(filename, encoding='utf-8') as file:\n",
        "        for line in file:\n",
        "            data.append(line.strip().split('\\t'))\n",
        "    return data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kkTxY3Mk9_nG"
      },
      "source": [
        "Нам понадобиться только файл validation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "PTVB9Tnp6j29"
      },
      "outputs": [],
      "source": [
        "validation_data = read_corpus('./data/validation.tsv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bTHfL-9y6j3F"
      },
      "source": [
        "Кол-во строк"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "z6ubXhIe6j3H",
        "scrolled": false
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "3760"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(validation_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kaOQblBy6j3M"
      },
      "source": [
        "Размер нескольких первых строк"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "yRx6e-Pe6j3M"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1 1001\n",
            "2 1001\n",
            "3 1001\n",
            "4 1001\n",
            "5 1001\n",
            "6 1001\n",
            "7 1001\n",
            "8 1001\n",
            "9 1001\n",
            "10 1001\n",
            "11 1001\n",
            "12 1001\n",
            "13 1001\n",
            "14 1001\n",
            "15 1001\n",
            "16 1001\n",
            "17 1001\n",
            "18 1001\n",
            "19 1001\n",
            "20 1001\n",
            "21 1001\n",
            "22 1001\n",
            "23 1001\n",
            "24 1001\n",
            "25 1001\n"
          ]
        }
      ],
      "source": [
        "for i in range(25):\n",
        "    print(i + 1, len(validation_data[i]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ySQQp0oQt1Ep"
      },
      "source": [
        "### Ранжирование без обучения"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iElEDhj-6j3R"
      },
      "source": [
        "Реализуйте функцию ранжирования кандидатов на основе косинусного расстояния. Функция должна по списку кандидатов вернуть отсортированный список пар (позиция в исходном списке кандидатов, кандидат). При этом позиция кандидата в полученном списке является его рейтингом (первый - лучший). Например, если исходный список кандидатов был [a, b, c], и самый похожий на исходный вопрос среди них - c, затем a, и в конце b, то функция должна вернуть список **[(2, c), (0, a), (1, b)]**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting scikit-learn\n",
            "  Downloading scikit_learn-1.7.2-cp311-cp311-win_amd64.whl.metadata (11 kB)\n",
            "Requirement already satisfied: numpy>=1.22.0 in c:\\project\\deeplearningschool\\.venv\\lib\\site-packages (from scikit-learn) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.8.0 in c:\\project\\deeplearningschool\\.venv\\lib\\site-packages (from scikit-learn) (1.13.1)\n",
            "Collecting joblib>=1.2.0 (from scikit-learn)\n",
            "  Downloading joblib-1.5.2-py3-none-any.whl.metadata (5.6 kB)\n",
            "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
            "  Downloading threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
            "Downloading scikit_learn-1.7.2-cp311-cp311-win_amd64.whl (8.9 MB)\n",
            "   ---------------------------------------- 0.0/8.9 MB ? eta -:--:--\n",
            "   ---------------------------------------- 0.0/8.9 MB ? eta -:--:--\n",
            "   ---- ----------------------------------- 1.0/8.9 MB 5.0 MB/s eta 0:00:02\n",
            "   ------- -------------------------------- 1.6/8.9 MB 5.2 MB/s eta 0:00:02\n",
            "   -------------- ------------------------- 3.1/8.9 MB 5.3 MB/s eta 0:00:02\n",
            "   ----------------------- ---------------- 5.2/8.9 MB 6.2 MB/s eta 0:00:01\n",
            "   ------------------------------- -------- 7.1/8.9 MB 6.8 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 8.9/8.9 MB 7.1 MB/s eta 0:00:00\n",
            "Downloading joblib-1.5.2-py3-none-any.whl (308 kB)\n",
            "Downloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
            "Installing collected packages: threadpoolctl, joblib, scikit-learn\n",
            "\n",
            "   ------------- -------------------------- 1/3 [joblib]\n",
            "   -------------------------- ------------- 2/3 [scikit-learn]\n",
            "   -------------------------- ------------- 2/3 [scikit-learn]\n",
            "   -------------------------- ------------- 2/3 [scikit-learn]\n",
            "   -------------------------- ------------- 2/3 [scikit-learn]\n",
            "   -------------------------- ------------- 2/3 [scikit-learn]\n",
            "   -------------------------- ------------- 2/3 [scikit-learn]\n",
            "   -------------------------- ------------- 2/3 [scikit-learn]\n",
            "   -------------------------- ------------- 2/3 [scikit-learn]\n",
            "   -------------------------- ------------- 2/3 [scikit-learn]\n",
            "   -------------------------- ------------- 2/3 [scikit-learn]\n",
            "   -------------------------- ------------- 2/3 [scikit-learn]\n",
            "   -------------------------- ------------- 2/3 [scikit-learn]\n",
            "   -------------------------- ------------- 2/3 [scikit-learn]\n",
            "   -------------------------- ------------- 2/3 [scikit-learn]\n",
            "   -------------------------- ------------- 2/3 [scikit-learn]\n",
            "   -------------------------- ------------- 2/3 [scikit-learn]\n",
            "   -------------------------- ------------- 2/3 [scikit-learn]\n",
            "   -------------------------- ------------- 2/3 [scikit-learn]\n",
            "   ---------------------------------------- 3/3 [scikit-learn]\n",
            "\n",
            "Successfully installed joblib-1.5.2 scikit-learn-1.7.2 threadpoolctl-3.6.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 25.1.1 -> 25.2\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "!pip3 install scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "K02JARKr6j3T"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from copy import deepcopy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "1yP8wJWj6j3X"
      },
      "outputs": [],
      "source": [
        "def rank_candidates(question, candidates, embeddings, tokenizer, dim=200):\n",
        "    \"\"\"\n",
        "        question: строка\n",
        "        candidates: массив строк(кандидатов) [a, b, c]\n",
        "        result: пары (начальная позиция, кандидат) [(2, c), (0, a), (1, b)]\n",
        "    \"\"\"\n",
        "    question_vector = question_to_vec(question, embeddings, tokenizer, dim).reshape(1, -1)\n",
        "\n",
        "    ranked_list = []\n",
        "    for i, candidate in enumerate(candidates):\n",
        "        candidate_vector = question_to_vec(candidate, embeddings, tokenizer, dim).reshape(1, -1)\n",
        "\n",
        "        similarity = cosine_similarity(question_vector, candidate_vector)[0][0]\n",
        "        ranked_list.append((similarity, i, candidate))\n",
        "\n",
        "    # Сортируем по убыванию схожести\n",
        "    ranked_list.sort(key=lambda x: x[0], reverse=True)\n",
        "\n",
        "    return [(item[1], item[2]) for item in ranked_list]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TnBszTb76j3c"
      },
      "source": [
        "Протестируйте работу функции на примерах ниже. Пусть $N=2$, то есть два эксперимента"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "xvQgtP176j3h"
      },
      "outputs": [],
      "source": [
        "questions = ['converting string to list', 'Sending array via Ajax fails']\n",
        "\n",
        "candidates = [['Convert Google results object (pure js) to Python object', # первый эксперимент\n",
        "               'C# create cookie from string and send it',\n",
        "               'How to use jQuery AJAX for an outside domain?'],\n",
        "\n",
        "              ['Getting all list items of an unordered list in PHP',      # второй эксперимент\n",
        "               'WPF- How to update the changes in list item of a list',\n",
        "               'select2 not displaying search results']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "bPj1JGFi6j3m"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[(1, 'C# create cookie from string and send it'), (0, 'Convert Google results object (pure js) to Python object'), (2, 'How to use jQuery AJAX for an outside domain?')]\n",
            "\n",
            "[(1, 'WPF- How to update the changes in list item of a list'), (0, 'Getting all list items of an unordered list in PHP'), (2, 'select2 not displaying search results')]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for question, q_candidates in zip(questions, candidates):\n",
        "        ranks = rank_candidates(question, q_candidates, wv_embeddings, tokenizer)\n",
        "        print(ranks)\n",
        "        print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jm4cidj56j3q"
      },
      "source": [
        "Для первого экперимента вы можете полностью сравнить ваши ответы и правильные ответы. Но для второго эксперимента два ответа на кандидаты будут <b>скрыты</b>(*)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "0LeKMIsn6j3s"
      },
      "outputs": [],
      "source": [
        "# должно вывести\n",
        "results = [[(1, 'C# create cookie from string and send it'),\n",
        "            (0, 'Convert Google results object (pure js) to Python object'),\n",
        "            (2, 'How to use jQuery AJAX for an outside domain?')],\n",
        "           [(0, 'Getting all list items of an unordered list in PHP'), #скрыт\n",
        "            (2, 'select2 not displaying search results'), #скрыт\n",
        "            (1, 'WPF- How to update the changes in list item of a list')]] #скрыт"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t1ttnIBe6j3x"
      },
      "source": [
        "Последовательность начальных индексов вы должны получить `для эксперимента 1`  1, 0, 2."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5WQgYDWd6j3y"
      },
      "source": [
        "#### ***Вопрос 5:***\n",
        "* Какую последовательность начальных индексов вы получили `для эксперимента 2`(перечисление без запятой и пробелов, например, `102` для первого эксперимента?\n",
        "\n",
        "021 для эксперемента 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fPllOY-Y6j30"
      },
      "source": [
        "Теперь мы можем оценить качество нашего метода. Запустите следующие два блока кода для получения результата. Обратите внимание, что вычисление расстояния между векторами занимает некоторое время (примерно 10 минут). Можете взять для validation 1000 примеров."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting tqdm\n",
            "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
            "Requirement already satisfied: colorama in c:\\project\\deeplearningschool\\.venv\\lib\\site-packages (from tqdm) (0.4.6)\n",
            "Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
            "Installing collected packages: tqdm\n",
            "Successfully installed tqdm-4.67.1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 25.1.1 -> 25.2\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "!pip3 install tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting ipywidgets\n",
            "  Downloading ipywidgets-8.1.7-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: comm>=0.1.3 in c:\\project\\deeplearningschool\\.venv\\lib\\site-packages (from ipywidgets) (0.2.3)\n",
            "Requirement already satisfied: ipython>=6.1.0 in c:\\project\\deeplearningschool\\.venv\\lib\\site-packages (from ipywidgets) (9.5.0)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in c:\\project\\deeplearningschool\\.venv\\lib\\site-packages (from ipywidgets) (5.14.3)\n",
            "Collecting widgetsnbextension~=4.0.14 (from ipywidgets)\n",
            "  Downloading widgetsnbextension-4.0.14-py3-none-any.whl.metadata (1.6 kB)\n",
            "Collecting jupyterlab_widgets~=3.0.15 (from ipywidgets)\n",
            "  Downloading jupyterlab_widgets-3.0.15-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: colorama in c:\\project\\deeplearningschool\\.venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.4.6)\n",
            "Requirement already satisfied: decorator in c:\\project\\deeplearningschool\\.venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (5.2.1)\n",
            "Requirement already satisfied: ipython-pygments-lexers in c:\\project\\deeplearningschool\\.venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (1.1.1)\n",
            "Requirement already satisfied: jedi>=0.16 in c:\\project\\deeplearningschool\\.venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.19.2)\n",
            "Requirement already satisfied: matplotlib-inline in c:\\project\\deeplearningschool\\.venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.1.7)\n",
            "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in c:\\project\\deeplearningschool\\.venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (3.0.52)\n",
            "Requirement already satisfied: pygments>=2.4.0 in c:\\project\\deeplearningschool\\.venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (2.19.2)\n",
            "Requirement already satisfied: stack_data in c:\\project\\deeplearningschool\\.venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.6.3)\n",
            "Requirement already satisfied: typing_extensions>=4.6 in c:\\project\\deeplearningschool\\.venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (4.15.0)\n",
            "Requirement already satisfied: wcwidth in c:\\project\\deeplearningschool\\.venv\\lib\\site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.13)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in c:\\project\\deeplearningschool\\.venv\\lib\\site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.5)\n",
            "Requirement already satisfied: executing>=1.2.0 in c:\\project\\deeplearningschool\\.venv\\lib\\site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (2.2.1)\n",
            "Requirement already satisfied: asttokens>=2.1.0 in c:\\project\\deeplearningschool\\.venv\\lib\\site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (3.0.0)\n",
            "Requirement already satisfied: pure-eval in c:\\project\\deeplearningschool\\.venv\\lib\\site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (0.2.3)\n",
            "Downloading ipywidgets-8.1.7-py3-none-any.whl (139 kB)\n",
            "Downloading jupyterlab_widgets-3.0.15-py3-none-any.whl (216 kB)\n",
            "Downloading widgetsnbextension-4.0.14-py3-none-any.whl (2.2 MB)\n",
            "   ---------------------------------------- 0.0/2.2 MB ? eta -:--:--\n",
            "   ---- ----------------------------------- 0.3/2.2 MB ? eta -:--:--\n",
            "   --------- ------------------------------ 0.5/2.2 MB 1.3 MB/s eta 0:00:02\n",
            "   -------------- ------------------------- 0.8/2.2 MB 1.4 MB/s eta 0:00:02\n",
            "   ------------------- -------------------- 1.0/2.2 MB 1.5 MB/s eta 0:00:01\n",
            "   ---------------------------- ----------- 1.6/2.2 MB 1.6 MB/s eta 0:00:01\n",
            "   --------------------------------- ------ 1.8/2.2 MB 1.6 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 2.2/2.2 MB 1.7 MB/s eta 0:00:00\n",
            "Installing collected packages: widgetsnbextension, jupyterlab_widgets, ipywidgets\n",
            "\n",
            "   -------------------------- ------------- 2/3 [ipywidgets]\n",
            "   ---------------------------------------- 3/3 [ipywidgets]\n",
            "\n",
            "Successfully installed ipywidgets-8.1.7 jupyterlab_widgets-3.0.15 widgetsnbextension-4.0.14\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 25.1.1 -> 25.2\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "!pip3 install ipywidgets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "Z3q9sxddz-yU"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "nu7K4mis6j32"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 27%|██▋       | 1000/3760 [03:28<09:34,  4.81it/s]\n"
          ]
        }
      ],
      "source": [
        "wv_ranking = []\n",
        "max_validation_examples = 1000\n",
        "for i, line in enumerate(tqdm(validation_data)):\n",
        "    if i == max_validation_examples:\n",
        "        break\n",
        "    q, *ex = line\n",
        "    ranks = rank_candidates(q, ex, wv_embeddings, tokenizer)\n",
        "    wv_ranking.append([r[0] for r in ranks].index(0) + 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "gDtS520v6j35",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 6/6 [00:00<00:00, 4464.40it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DCG@   1: 0.285 | Hits@   1: 0.285\n",
            "DCG@   5: 0.342 | Hits@   5: 0.393\n",
            "DCG@  10: 0.360 | Hits@  10: 0.449\n",
            "DCG@ 100: 0.406 | Hits@ 100: 0.679\n",
            "DCG@ 500: 0.431 | Hits@ 500: 0.879\n",
            "DCG@1000: 0.444 | Hits@1000: 1.000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "for k in tqdm([1, 5, 10, 100, 500, 1000]):\n",
        "    print(\"DCG@%4d: %.3f | Hits@%4d: %.3f\" % (k, dcg_score(wv_ranking, k), k, hits_count(wv_ranking, k)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SZ16fNZ4mxTC"
      },
      "source": [
        "Из формул выше можно понять, что\n",
        "\n",
        "- $ \\text{Hits@K} $ **монотонно неубывающая функция** $ K $, которая стремится к 1 при $ K \\to \\infty $.\n",
        "\n",
        "- $ \\text{DCG@K} $ **монотонно неубывающая функция** $ K $, но рост замедляется с увеличением $ K $ из-за убывания веса $ \\frac{1}{\\log_2(1 + \\text{rank}_{q'_i})} $."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LL6_Rjg3InL8"
      },
      "source": [
        "### Эмбеддинги, обученные на корпусе похожих вопросов"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "iNvbpR5gJIPz"
      },
      "outputs": [],
      "source": [
        "train_data = read_corpus('./data/train.tsv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nr281ZyEJfjT"
      },
      "source": [
        "Улучшите качество модели.<br>Склеим вопросы в пары и обучим на них модель Word2Vec из gensim. Выберите размер window. Объясните свой выбор.\n",
        "\n",
        "***Рассмотрим подробнее*** данное склеивание.\n",
        "\n",
        "1. Каждая строка из train_data разбивается на вопрос (question) и список кандидатов.\n",
        "\n",
        "2. Для каждого кандидата вопрос склеивается с ним в одну строку.\n",
        "\n",
        "3. Склеенная строка (combined_text) токенизируется, и полученный список токенов добавляется в общий корпус (corpus).\n",
        "\n",
        "***Пример***\n",
        "\n",
        "    Вопрос: \"What is Python?\"\n",
        "    Кандидаты: [\"Python is a programming language\", \"Java is another language\"]\n",
        "    Склеенные строки:\n",
        "        \"What is Python? Python is a programming language\"\n",
        "        \"What is Python? Java is another language\"\n",
        "         \n",
        "    Токенизированные списки:\n",
        "        ['what', 'is', 'python', 'python', 'is', 'a', 'programming', 'language']\n",
        "        ['what', 'is', 'python', 'java', 'is', 'another', 'language']\n",
        "         \n",
        "     "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "9NNgRRiu8-LL"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Why prefer start + (end - start) / 2 over (start + end) / 2 when calculating the middle of an array?',\n",
              " 'Why are binary search index computed this way?']"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_data[5566]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "f6Y46SSQMTL0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Пример первой записи в корпусе: ['con', 'onv', 'nve', 'ver', 'ert', 'rti', 'tin', 'ing', 'ng ', 'g s', ' st', 'str', 'tri', 'rin', 'ing', 'ng ', 'g t', ' to', 'to ', 'o l', ' li', 'lis', 'ist', 'st ', 't c', ' co', 'con', 'onv', 'nve', 'ver', 'ert', 'rt ', 't g', ' go', 'goo', 'oog', 'ogl', 'gle', 'le ', 'e r', ' re', 'res', 'esu', 'sul', 'ult', 'lts', 'ts ', 's o', ' ob', 'obj', 'bje', 'jec', 'ect', 'ct ', 't (', ' (p', '(pu', 'pur', 'ure', 're ', 'e j', ' js', 'js)', 's) ', ') t', ' to', 'to ', 'o p', ' py', 'pyt', 'yth', 'tho', 'hon', 'on ', 'n o', ' ob', 'obj', 'bje', 'jec', 'ect']\n"
          ]
        }
      ],
      "source": [
        "# Создаем общий корпус текстов\n",
        "corpus = []\n",
        "\n",
        "#  TODO: ВОЗМОЖНО непраильно, перезапустить !!!!!!!!!!\n",
        "\n",
        "'''your code'''\n",
        "for texts in train_data:\n",
        "    combined_text = texts[0] + ' ' + texts[1]\n",
        "    tokens = tokenizer.tokenize(combined_text.lower())\n",
        "    corpus.append(tokens)\n",
        "\n",
        "print(f\"Пример первой записи в корпусе: {corpus[0]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "QuJzAM0cI-UH"
      },
      "outputs": [],
      "source": [
        "from gensim.models import Word2Vec\n",
        "embeddings_trained = Word2Vec(\n",
        "    sentences=corpus,        # Корпус токенизированных текстов\n",
        "    vector_size=200,         # Размерность векторов\n",
        "    window=8,                # Размер окна контекста\n",
        "    min_count=1,             # Минимальная частота слов\n",
        "    workers=4                # Количество потоков\n",
        ").wv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "OQonbm4nMenD"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 27%|██▋       | 1000/3760 [03:24<09:23,  4.89it/s]\n"
          ]
        }
      ],
      "source": [
        "wv_ranking = []\n",
        "max_validation_examples = 1000\n",
        "for i, line in enumerate(tqdm(validation_data)):\n",
        "    if i == max_validation_examples:\n",
        "        break\n",
        "    q, *ex = line\n",
        "    ranks = rank_candidates(q, ex, embeddings_trained, tokenizer)\n",
        "    wv_ranking.append([r[0] for r in ranks].index(0) + 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "3kahBUPGMgGR"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 6/6 [00:00<00:00, 1907.51it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DCG@   1: 0.202 | Hits@   1: 0.202\n",
            "DCG@   5: 0.253 | Hits@   5: 0.298\n",
            "DCG@  10: 0.268 | Hits@  10: 0.347\n",
            "DCG@ 100: 0.317 | Hits@ 100: 0.589\n",
            "DCG@ 500: 0.347 | Hits@ 500: 0.827\n",
            "DCG@1000: 0.365 | Hits@1000: 1.000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "for k in tqdm([1, 5, 10, 100, 500, 1000]):\n",
        "    print(\"DCG@%4d: %.3f | Hits@%4d: %.3f\" % (k, dcg_score(wv_ranking, k), k, hits_count(wv_ranking, k)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Другая токенизация из модуля не словами, а n граммами (3):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['hel',\n",
              " 'ell',\n",
              " 'llo',\n",
              " 'lo,',\n",
              " 'o, ',\n",
              " ', m',\n",
              " ' my',\n",
              " 'my ',\n",
              " 'y 1',\n",
              " ' 1.',\n",
              " '1.f',\n",
              " '.fr',\n",
              " 'fri',\n",
              " 'rie',\n",
              " 'ien',\n",
              " 'end']"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "class MyTokenizer:\n",
        "    def __init__(self):\n",
        "        pass\n",
        "    def tokenize(self, text, n=3):\n",
        "        text = text.lower()\n",
        "\n",
        "        ngrams = []\n",
        "        for i in range(len(text) - n + 1):\n",
        "            ngrams.append(text[i:i+n])\n",
        "\n",
        "        return ngrams\n",
        "tokenizer = MyTokenizer()\n",
        "tokenizer.tokenize(\"Hello, my 1.friend\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Пример первой записи в корпусе: ['con', 'onv', 'nve', 'ver', 'ert', 'rti', 'tin', 'ing', 'ng ', 'g s', ' st', 'str', 'tri', 'rin', 'ing', 'ng ', 'g t', ' to', 'to ', 'o l', ' li', 'lis', 'ist', 'st ', 't c', ' co', 'con', 'onv', 'nve', 'ver', 'ert', 'rt ', 't g', ' go', 'goo', 'oog', 'ogl', 'gle', 'le ', 'e r', ' re', 'res', 'esu', 'sul', 'ult', 'lts', 'ts ', 's o', ' ob', 'obj', 'bje', 'jec', 'ect', 'ct ', 't (', ' (p', '(pu', 'pur', 'ure', 're ', 'e j', ' js', 'js)', 's) ', ') t', ' to', 'to ', 'o p', ' py', 'pyt', 'yth', 'tho', 'hon', 'on ', 'n o', ' ob', 'obj', 'bje', 'jec', 'ect']\n"
          ]
        }
      ],
      "source": [
        "# Создаем общий корпус текстов\n",
        "corpus = []\n",
        "\n",
        "#  TODO: ВОЗМОЖНО непраильно, перезапустить !!!!!!!!!!\n",
        "\n",
        "'''your code'''\n",
        "for texts in train_data:\n",
        "    combined_text = texts[0] + ' ' + texts[1]\n",
        "    tokens = tokenizer.tokenize(combined_text.lower())\n",
        "    corpus.append(tokens)\n",
        "\n",
        "print(f\"Пример первой записи в корпусе: {corpus[0]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [],
      "source": [
        "embeddings_trained = Word2Vec(\n",
        "    sentences=corpus,        # Корпус токенизированных текстов\n",
        "    vector_size=200,         # Размерность векторов\n",
        "    window=8,                # Размер окна контекста\n",
        "    min_count=1,             # Минимальная частота слов\n",
        "    workers=4                # Количество потоков\n",
        ").wv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 27%|██▋       | 1000/3760 [04:16<11:49,  3.89it/s]\n",
            "100%|██████████| 6/6 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DCG@   1: 0.286 | Hits@   1: 0.286\n",
            "DCG@   5: 0.339 | Hits@   5: 0.386\n",
            "DCG@  10: 0.355 | Hits@  10: 0.438\n",
            "DCG@ 100: 0.394 | Hits@ 100: 0.638\n",
            "DCG@ 500: 0.424 | Hits@ 500: 0.867\n",
            "DCG@1000: 0.438 | Hits@1000: 1.000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "wv_ranking = []\n",
        "max_validation_examples = 1000\n",
        "for i, line in enumerate(tqdm(validation_data)):\n",
        "    if i == max_validation_examples:\n",
        "        break\n",
        "    q, *ex = line\n",
        "    ranks = rank_candidates(q, ex, embeddings_trained, tokenizer)\n",
        "    wv_ranking.append([r[0] for r in ranks].index(0) + 1)\n",
        "for k in tqdm([1, 5, 10, 100, 500, 1000]):\n",
        "    print(\"DCG@%4d: %.3f | Hits@%4d: %.3f\" % (k, dcg_score(wv_ranking, k), k, hits_count(wv_ranking, k)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "разделение на n-граммы увеличело результаты, но не на слишком колосальные результаты. 0.08. Причем исользовались n-граммы просто разделяюшие весь текст по 3 символа (с пробелами)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting nltk\n",
            "  Downloading nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting click (from nltk)\n",
            "  Downloading click-8.3.0-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: joblib in c:\\project\\deeplearningschool\\.venv\\lib\\site-packages (from nltk) (1.5.2)\n",
            "Collecting regex>=2021.8.3 (from nltk)\n",
            "  Downloading regex-2025.9.18-cp311-cp311-win_amd64.whl.metadata (41 kB)\n",
            "Requirement already satisfied: tqdm in c:\\project\\deeplearningschool\\.venv\\lib\\site-packages (from nltk) (4.67.1)\n",
            "Requirement already satisfied: colorama in c:\\project\\deeplearningschool\\.venv\\lib\\site-packages (from click->nltk) (0.4.6)\n",
            "Downloading nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
            "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
            "   ------ --------------------------------- 0.3/1.5 MB ? eta -:--:--\n",
            "   --------------------------- ------------ 1.0/1.5 MB 5.0 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 1.5/1.5 MB 3.3 MB/s eta 0:00:00\n",
            "Downloading regex-2025.9.18-cp311-cp311-win_amd64.whl (276 kB)\n",
            "Downloading click-8.3.0-py3-none-any.whl (107 kB)\n",
            "Installing collected packages: regex, click, nltk\n",
            "\n",
            "   ------------- -------------------------- 1/3 [click]\n",
            "   -------------------------- ------------- 2/3 [nltk]\n",
            "   -------------------------- ------------- 2/3 [nltk]\n",
            "   -------------------------- ------------- 2/3 [nltk]\n",
            "   -------------------------- ------------- 2/3 [nltk]\n",
            "   -------------------------- ------------- 2/3 [nltk]\n",
            "   -------------------------- ------------- 2/3 [nltk]\n",
            "   -------------------------- ------------- 2/3 [nltk]\n",
            "   ---------------------------------------- 3/3 [nltk]\n",
            "\n",
            "Successfully installed click-8.3.0 nltk-3.9.1 regex-2025.9.18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 25.1.1 -> 25.2\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "!pip3 install nltk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {},
      "outputs": [],
      "source": [
        "from nltk import ngrams"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['hel', 'ell', 'llo', 'my', '1', 'fri', 'rie', 'ien', 'end']"
            ]
          },
          "execution_count": 97,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "class MyTokenizer:\n",
        "    def __init__(self):\n",
        "        pass\n",
        "    def tokenize(self, text: str, n=3):\n",
        "        text = re.sub(r'[^\\w\\s]', '', text).lower()\n",
        "\n",
        "        s = []\n",
        "        # 2. Разбиение текста на слова и итерация по ним\n",
        "        for word in text.split():\n",
        "            # 3. Генерация символьных n-грамм для каждого слова\n",
        "            if len(word) >= n:\n",
        "                for i in range(len(word) - n + 1):\n",
        "                    s.append(word[i:i+n])\n",
        "            else:\n",
        "                s.append(word)\n",
        "\n",
        "        return s\n",
        "tokenizer = MyTokenizer()\n",
        "tokenizer.tokenize(\"Hello, my 1. friend\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Пример первой записи в корпусе: ['con', 'onv', 'nve', 'ver', 'ert', 'rti', 'tin', 'ing', 'str', 'tri', 'rin', 'ing', 'to', 'lis', 'ist', 'con', 'onv', 'nve', 'ver', 'ert', 'goo', 'oog', 'ogl', 'gle', 'res', 'esu', 'sul', 'ult', 'lts', 'obj', 'bje', 'jec', 'ect', 'pur', 'ure', 'js', 'to', 'pyt', 'yth', 'tho', 'hon', 'obj', 'bje', 'jec', 'ect']\n"
          ]
        }
      ],
      "source": [
        "# Создаем общий корпус текстов\n",
        "corpus = []\n",
        "\n",
        "\n",
        "'''your code'''\n",
        "for texts in train_data:\n",
        "    combined_text = texts[0] + ' ' + texts[1]\n",
        "    tokens = tokenizer.tokenize(combined_text.lower())\n",
        "    corpus.append(tokens)\n",
        "\n",
        "print(f\"Пример первой записи в корпусе: {corpus[0]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {},
      "outputs": [],
      "source": [
        "embeddings_trained = Word2Vec(\n",
        "    sentences=corpus,        # Корпус токенизированных текстов\n",
        "    vector_size=200,         # Размерность векторов\n",
        "    window=8,                # Размер окна контекста\n",
        "    min_count=1,             # Минимальная частота слов\n",
        "    workers=4                # Количество потоков\n",
        ").wv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 27%|██▋       | 1000/3760 [03:59<11:01,  4.18it/s]\n",
            "100%|██████████| 6/6 [00:00<00:00, 6007.60it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DCG@   1: 0.377 | Hits@   1: 0.377\n",
            "DCG@   5: 0.459 | Hits@   5: 0.533\n",
            "DCG@  10: 0.474 | Hits@  10: 0.578\n",
            "DCG@ 100: 0.515 | Hits@ 100: 0.781\n",
            "DCG@ 500: 0.534 | Hits@ 500: 0.926\n",
            "DCG@1000: 0.542 | Hits@1000: 1.000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "wv_ranking = []\n",
        "max_validation_examples = 1000\n",
        "for i, line in enumerate(tqdm(validation_data)):\n",
        "    if i == max_validation_examples:\n",
        "        break\n",
        "    q, *ex = line\n",
        "    ranks = rank_candidates(q, ex, embeddings_trained, tokenizer)\n",
        "    wv_ranking.append([r[0] for r in ranks].index(0) + 1)\n",
        "for k in tqdm([1, 5, 10, 100, 500, 1000]):\n",
        "    print(\"DCG@%4d: %.3f | Hits@%4d: %.3f\" % (k, dcg_score(wv_ranking, k), k, hits_count(wv_ranking, k)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Результаты еще увеличились при дополнительном предпроцессинге текста."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tY8PxB0j-ThG"
      },
      "source": [
        "### Замечание:\n",
        "Решить эту задачу с помощью обучения полноценной нейронной сети будет вам предложено, как часть задания в одной из домашних работ по теме \"Диалоговые системы\"."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vymVj8IxO2PO"
      },
      "source": [
        "Напишите свой вывод о полученных результатах.\n",
        "* Какой принцип токенизации даёт качество лучше и почему?\n",
        "\n",
        "N-грамм, потому что мы кодируем не отдельные слова, а набор грамм, которые лучше работают.\n",
        "\n",
        "* Помогает ли нормализация слов?\n",
        "\n",
        "Да помогает, так как очищает данные от лишнего.\n",
        "\n",
        "* Какие эмбеддинги лучше справляются с задачей и почему?\n",
        "\n",
        "Лучше уже заготовленные, но если обучить Word2Vec лучше, то возможно он будет лучше, под определенный набор данных.\n",
        "\n",
        "* Почему получилось плохое качество решения задачи?\n",
        "\n",
        "Токинезация слов, \n",
        "\n",
        "* Предложите свой подход к решению задачи.\n",
        "\n",
        "\n",
        "Лучше токинизировать слова на n-граммы (уже преведенно в экспирименте, значительный прирост в качестве), \n",
        "\n",
        "## Вывод:\n",
        "\n",
        "Качество модели зависит от качества данных\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "emODHztAQUQz"
      },
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "deeplearningschool-py3.11",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
